---
phase: 02-api-routes-client-layer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/db/dryingLogs.js
  - backend/src/routes/drying.js
  - backend/src/routes/apexJobs.js
  - backend/package.json
autonomous: true

must_haves:
  truths:
    - "Every drying entity (log, chamber, room, ref point, baseline, visit, note) has working CRUD endpoints under /api/apex-jobs/:jobId/drying/*"
    - "Bulk save endpoint accepts atmospheric + moisture + equipment arrays and saves all in a single transaction"
    - "Photo upload endpoint accepts multipart/form-data, processes images with sharp (auto-orient, resize 1920px max, thumbnail 300px), returns paths"
    - "Photo serving endpoint verifies job ownership before sending file (not publicly accessible)"
    - "Visit creation auto-assigns the next visit_number (server-side MAX+1, not client-provided)"
  artifacts:
    - path: "backend/src/routes/drying.js"
      provides: "All drying REST endpoints with photo upload/serving"
      contains: "mergeParams: true"
    - path: "backend/src/db/dryingLogs.js"
      provides: "Complete CRUD (including update/delete) for all drying entities"
      exports: ["updateChamber", "deleteChamber", "updateRoom", "deleteRoom", "updateRefPoint", "deleteVisit", "deleteNote", "getLogById"]
    - path: "backend/src/routes/apexJobs.js"
      provides: "Drying sub-router mounted at /:id/drying"
      contains: "require('./drying')"
  key_links:
    - from: "backend/src/routes/drying.js"
      to: "backend/src/db/dryingLogs.js"
      via: "require('../db/dryingLogs')"
      pattern: "dryingLogs\\."
    - from: "backend/src/routes/apexJobs.js"
      to: "backend/src/routes/drying.js"
      via: "router.use('/:id/drying', dryingRoutes)"
      pattern: "require\\('./drying'\\)"
    - from: "backend/src/routes/drying.js"
      to: "sharp"
      via: "require('sharp') for photo processing"
      pattern: "sharp\\("
---

<objective>
Create all backend REST API routes for drying log data under `/api/apex-jobs/:jobId/drying/*`, including CRUD for every entity, bulk save for visit data, and a photo upload/processing pipeline using sharp.

Purpose: Phase 2 bridges the Phase 1 database layer to the frontend. Without API routes, no UI can read or write drying data. The bulk save endpoint is critical for atomic visit data submission from the field.

Output: `backend/src/routes/drying.js` with ~25 endpoints, extended `dryingLogs.js` with missing CRUD functions, sharp installed as dependency.
</objective>

<execution_context>
@C:/Users/jaker/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/jaker/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-api-routes-client-layer/02-RESEARCH.md
@.planning/phases/01-schema-gpp-engine/01-02-SUMMARY.md
@backend/src/db/dryingLogs.js
@backend/src/routes/apexJobs.js
@backend/src/routes/uploads.js
@backend/src/index.js
@backend/package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend dryingLogs.js with missing update/delete CRUD and helper queries</name>
  <files>backend/src/db/dryingLogs.js</files>
  <action>
Add the following prepared statements and exported functions to `backend/src/db/dryingLogs.js`. Place new prepared statements in the existing PREPARED STATEMENTS section, grouped by entity. Add new exports to the existing module.exports object.

**New prepared statements to add:**

```javascript
// Logs - additional queries
const getLogById = db.prepare('SELECT * FROM drying_logs WHERE id = ?');

// Chambers - update/delete
const getChamberById = db.prepare('SELECT * FROM drying_chambers WHERE id = ?');
const updateChamberStmt = db.prepare("UPDATE drying_chambers SET name = ?, color = ?, position = ?, updated_at = datetime('now') WHERE id = ?");
const deleteChamberStmt = db.prepare('DELETE FROM drying_chambers WHERE id = ?');

// Rooms - update/delete + query by log
const getRoomById = db.prepare('SELECT * FROM drying_rooms WHERE id = ?');
const updateRoomStmt = db.prepare("UPDATE drying_rooms SET name = ?, position = ?, chamber_id = ?, updated_at = datetime('now') WHERE id = ?");
const deleteRoomStmt = db.prepare('DELETE FROM drying_rooms WHERE id = ?');
const getRoomsByLogId = db.prepare(`
  SELECT r.* FROM drying_rooms r
  JOIN drying_chambers c ON r.chamber_id = c.id
  WHERE c.log_id = ?
  ORDER BY c.position, r.position
`);

// Reference points - update
const updateRefPointStmt = db.prepare('UPDATE drying_ref_points SET material_code = ?, label = ? WHERE id = ?');

// Visits - delete + auto-number helper
const deleteVisitStmt = db.prepare('DELETE FROM drying_visits WHERE id = ?');
const getMaxVisitNumber = db.prepare('SELECT MAX(visit_number) as max_num FROM drying_visits WHERE log_id = ?');

// Visit notes - delete + get by id
const getNoteById = db.prepare('SELECT * FROM drying_visit_notes WHERE id = ?');
const deleteNoteStmt = db.prepare('DELETE FROM drying_visit_notes WHERE id = ?');
```

**New exports to add to module.exports:**

```javascript
// Log by ID (not job_id)
getLogById: (id) => getLogById.get(id),

// Chamber update/delete
getChamberById: (id) => getChamberById.get(id),
updateChamber: (id, data) => {
  updateChamberStmt.run(data.name, data.color, data.position, id);
  return getChamberById.get(id);
},
deleteChamber: (id) => deleteChamberStmt.run(id),

// Room update/delete + query by log
getRoomById: (id) => getRoomById.get(id),
updateRoom: (id, data) => {
  updateRoomStmt.run(data.name, data.position, data.chamber_id, id);
  return getRoomById.get(id);
},
deleteRoom: (id) => deleteRoomStmt.run(id),
getRoomsByLogId: (logId) => getRoomsByLogId.all(logId),

// Reference point update
updateRefPoint: (id, data) => {
  updateRefPointStmt.run(data.material_code, data.label, id);
  return getRefPointById.get(id);
},

// Visit delete + auto-number creation
deleteVisit: (id) => deleteVisitStmt.run(id),
createVisit: (logId, visitedAt) => {
  const result = getMaxVisitNumber.get(logId);
  const nextNum = (result?.max_num || 0) + 1;
  const id = uuidv4();
  insertVisit.run(id, logId, nextNum, visitedAt || new Date().toISOString());
  return getVisitById.get(id);
},

// Visit note delete + get by id
getNoteById: (id) => getNoteById.get(id),
deleteNote: (id) => deleteNoteStmt.run(id),
```

**Important naming note:** Some statement const names clash with export function names (e.g., `insertChamber` is both a prepared statement and an export). Use `Stmt` suffix on NEW prepared statement consts where the base name is already taken (e.g., `updateChamberStmt`, `deleteChamberStmt`). Do NOT rename existing prepared statements.

**Do NOT modify** any existing prepared statements, functions, or exports. Only add new ones.
  </action>
  <verify>
Run `node -e "const dl = require('./backend/src/db/dryingLogs'); console.log(Object.keys(dl).sort().join(', '))"` and confirm these new exports exist: `createVisit`, `deleteChamber`, `deleteNote`, `deleteRoom`, `deleteVisit`, `getChamberById`, `getLogById`, `getNoteById`, `getRoomById`, `getRoomsByLogId`, `updateChamber`, `updateRefPoint`, `updateRoom`.
  </verify>
  <done>dryingLogs.js exports all CRUD operations needed by the API routes: the 13 new functions listed above plus all existing exports still work.</done>
</task>

<task type="auto">
  <name>Task 2: Create drying.js route file with all REST endpoints, photo pipeline, and mount on apexJobs</name>
  <files>backend/src/routes/drying.js, backend/src/routes/apexJobs.js, backend/package.json</files>
  <action>
**Step 1: Install sharp**

Run `cd backend && npm install sharp` to add sharp as a dependency.

**Step 2: Create `backend/src/routes/drying.js`**

Create a new Express sub-router with `{ mergeParams: true }` (CRITICAL -- without this, `req.params.id` from the parent apexJobs router is undefined).

The parent apexJobs.js router already applies `authMiddleware` and guest-role blocking for all nested routes. The drying sub-router does NOT need its own `router.use(authMiddleware)`.

**Route structure -- implement ALL of these endpoints:**

```
DRYING LOGS (one per job):
  GET    /log                         -> dryingLogs.getLogByJobId(req.params.id)
  POST   /log                         -> dryingLogs.createDryingLog(req.params.id)

CHAMBERS:
  GET    /chambers                    -> dryingLogs.getChambersByLogId(log.id)
  POST   /chambers                    -> dryingLogs.insertChamber(log.id, name, color, position)
  PATCH  /chambers/:chamberId         -> dryingLogs.updateChamber(chamberId, {name, color, position})
  DELETE /chambers/:chamberId         -> dryingLogs.deleteChamber(chamberId)

ROOMS:
  GET    /rooms                       -> dryingLogs.getRoomsByLogId(log.id) (all rooms across chambers)
  GET    /rooms?chamberId=X           -> dryingLogs.getRoomsByChamber(chamberId)
  POST   /rooms                       -> dryingLogs.insertRoom(chamberId, name, position)
  PATCH  /rooms/:roomId               -> dryingLogs.updateRoom(roomId, {name, position, chamber_id})
  DELETE /rooms/:roomId               -> dryingLogs.deleteRoom(roomId)

REFERENCE POINTS:
  GET    /ref-points                  -> dryingLogs.getRefPointsByLog(log.id)
  POST   /ref-points                  -> dryingLogs.addRefPoint(log.id, roomId, materialCode, label)
  PATCH  /ref-points/:rpId            -> dryingLogs.updateRefPoint(rpId, {material_code, label})
  POST   /ref-points/:rpId/demolish   -> dryingLogs.demolishRefPoint(rpId, visitId)

BASELINES:
  GET    /baselines                   -> dryingLogs.getBaselinesByLog(log.id)
  PUT    /baselines                   -> dryingLogs.upsertBaseline(log.id, materialCode, baselineValue)

VISITS:
  GET    /visits                      -> dryingLogs.getVisitsByLog(log.id)
  POST   /visits                      -> dryingLogs.createVisit(log.id, visitedAt)  [auto-assigns visit_number]
  GET    /visits/:visitId             -> Composite: visit + atmospheric + moisture + equipment + notes
  POST   /visits/:visitId/save        -> Bulk save (see below)
  DELETE /visits/:visitId             -> dryingLogs.deleteVisit(visitId)

VISIT NOTES:
  GET    /visits/:visitId/notes       -> dryingLogs.getNotesByVisit(visitId)
  POST   /visits/:visitId/notes       -> dryingLogs.insertNote(visitId, content, photos)
  DELETE /visits/:visitId/notes/:noteId -> dryingLogs.deleteNote(noteId)

PHOTOS:
  POST   /photos                      -> multer upload + sharp processing
  GET    /photos/:filename            -> Auth-gated file serving
```

**Every route handler pattern (follow existing apexJobs.js style):**
```javascript
router.get('/example', (req, res) => {
  try {
    // req.params.id is the jobId from parent router (via mergeParams)
    const log = dryingLogs.getLogByJobId(req.params.id);
    if (!log) return res.status(404).json({ error: 'No drying log for this job' });
    // ... DB operation ...
    res.json(result);
  } catch (err) {
    console.error('Error description:', err);
    res.status(500).json({ error: 'Failed to ...' });
  }
});
```

**Helper function** at top of file -- many routes need the log, so extract:
```javascript
function requireLog(jobId) {
  const log = dryingLogs.getLogByJobId(jobId);
  return log; // Caller checks null and returns 404
}
```

**Bulk save endpoint (`POST /visits/:visitId/save`):**
- Request body shape: `{ atmospheric: [...], moisture: [...], equipment: [...] }`
- Verify visit exists and belongs to this job's log
- Import `db` from `../db/schema` to create an outer transaction wrapping all three saves
- Each sub-array is optional (client may only update atmospheric without moisture)
- Call `dryingLogs.saveAtmosphericReadings(visitId, atmospheric)`, `dryingLogs.saveMoistureReadings(visitId, moisture, log.id)`, `dryingLogs.saveEquipment(visitId, equipment)` inside the outer transaction
- Return `{ success: true, visit: { ...visitData } }`

**Composite visit GET (`GET /visits/:visitId`):**
- Returns the visit record plus all child data:
```json
{
  "visit": { ...visitRow },
  "atmospheric": [...],
  "moisture": [...],
  "equipment": [...],
  "notes": [...]
}
```

**Photo upload (`POST /photos`):**
- Use multer with disk storage to a temp directory (`/data/uploads/tmp`)
- Accept field name `photos`, allow multiple files: `upload.array('photos', 20)`
- Only allow image MIME types: `image/jpeg`, `image/png`, `image/webp`, `image/heic`, `image/heif`
- For each uploaded file, process with sharp:
  - `sharp(inputPath).autoOrient().resize({ width: 1920, height: 1920, fit: 'inside', withoutEnlargement: true }).jpeg({ quality: 85 }).toFile(fullPath)`
  - `sharp(inputPath).autoOrient().resize({ width: 300, height: 300, fit: 'inside' }).jpeg({ quality: 70 }).toFile(thumbPath)`
- Output directory: `/data/uploads/drying/{jobId}/`
- Filename: `{uuid}.jpg` and `{uuid}_thumb.jpg`
- Wrap sharp processing in try/finally to always unlink temp file
- Return array of `{ id, path, thumbPath }` for each processed photo

**Photo serving (`GET /photos/:filename`):**
- Validate filename (no path separators, no `..`)
- Resolve to `/data/uploads/drying/{jobId}/{filename}`
- Verify resolved path is within `/data/uploads/drying/`
- `res.sendFile(resolvedPath)`

**Step 3: Mount sub-router in apexJobs.js**

At the bottom of `backend/src/routes/apexJobs.js`, just BEFORE `module.exports = router;`, add:

```javascript
// Drying log sub-routes
const dryingRoutes = require('./drying');
router.use('/:id/drying', dryingRoutes);
```

This placement ensures drying routes inherit the existing auth middleware and guest-role blocking that is applied via `router.use(authMiddleware, ...)` at the top of apexJobs.js.
  </action>
  <verify>
1. Run `cd backend && node -e "require('./src/routes/drying')"` to confirm the module loads without errors.
2. Run `node -e "const pkg = require('./backend/package.json'); console.log('sharp:', pkg.dependencies.sharp)"` to confirm sharp is in dependencies.
3. Run `cd backend && node -e "const app = require('./src/index'); console.log('Server loaded')"` to confirm the full app starts without import errors (Ctrl+C after confirmation).
  </verify>
  <done>
- `backend/src/routes/drying.js` exists with all 25+ endpoints listed above
- `backend/src/routes/apexJobs.js` mounts drying sub-router at `/:id/drying`
- `sharp` is listed in backend/package.json dependencies
- The full app loads without errors
  </done>
</task>

</tasks>

<verification>
After both tasks are complete, verify the full endpoint set by starting the server and confirming route registration:

1. `cd backend && node -e "const app = require('./src/index'); setTimeout(() => process.exit(0), 1000)"` -- app starts cleanly
2. Module load test: `node -e "const dl = require('./backend/src/db/dryingLogs'); const keys = Object.keys(dl); console.log(keys.length, 'exports'); console.log(keys.filter(k => ['updateChamber','deleteChamber','updateRoom','deleteRoom','updateRefPoint','deleteVisit','deleteNote','getLogById','createVisit','getRoomsByLogId'].includes(k)).length, 'new exports found')"` -- should report 10 new exports found
3. Sharp installed: `node -e "require('sharp'); console.log('sharp OK')"` from backend directory
</verification>

<success_criteria>
- All 25+ REST endpoints defined in drying.js covering logs, chambers, rooms, ref points, baselines, visits, notes, and photos
- Bulk save endpoint wraps atmospheric + moisture + equipment in a single outer transaction
- Photo upload processes images with sharp (auto-orient, resize 1920px, thumbnail 300px, JPEG compression)
- Photo serving is auth-gated (inherits from parent router auth middleware)
- dryingLogs.js extended with update/delete functions for all entities
- Visit creation auto-assigns next visit_number server-side
- Sub-router mounted on apexJobs.js with mergeParams: true
- Full app starts without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-api-routes-client-layer/02-01-SUMMARY.md`
</output>
